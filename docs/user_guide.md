# Руководство пользователя

## Содержание
- [Запуск через информационную базу "RDV-LogA: Анализ технологического журнала"](#запуск-через-информационную-базу-анализ-технологического-журнала)
  - [1. Подготовка](#1-подготовка)
    - [Конфигурация технологического журнала](#конфигурация-технологического-журнала)
  - [2. Запуск обработки](#2-запуск-обработки)
  - [3. Настройка параметров](#3-настройка-параметров)
  - [4. Контроль CPU](#4-контроль-cpu)
  - [5. Выбор шаблонов анализа](#5-выбор-шаблонов-анализа)
  - [6. Настройка каталогов анализа](#6-настройка-каталогов-анализа)
  - [7. Запуск анализа](#7-запуск-анализа)
  - [8. Результаты анализа](#8-результаты-анализа)
  - [9. Ручной запуск](#9-ручной-запуск)
- [Настройка шаблона анализа](#настройка-шаблона-анализа)
  - [1. Основные настройки](#1-основные-настройки)
    - [Обязательные параметры](#обязательные-параметры)
    - [Работа с колонками](#работа-с-колонками)
    - [Каталоги анализа](#каталоги-анализа)
    - [Агрегация «Интервалы»](#агрегация-интервалы)
    - [Агрегация «Округление времени»](#агрегация-округление-времени)
	
## Запуск через информационную базу "Анализ технологического журнала"

### 1. Подготовка
Скачайте информационную базу с готовыми шаблонами анализа: [Каталог releases_1c](../releases_1c)  

Установите необходимые зависимости: 
```bash
pip install polars numpy xlsxwriter tqdm
```
Подробнее см. раздел *Установка* в [README.md](../README.md)

#### Конфигурация технологического журнала
Включите технологический журнал. Выполните сбор данных за 1 день и более. 
Рекомендуется собрать данные от 3-х недель. Это повысит вероятность того, что в журнал попадут операции, которые выполняются один раз в месяц в определенный период.
Пример конфигурации технологического журнала [logcfg.xml](example/logcfg.xml) 

---

### 2. Запуск обработки
Запустите обработку **"Анализ технологического журнала"**:  
![start_analysis](img/start_analysis.jpg)

Выберите каталог, в котором расположены файлы технологического журнала:  
![select_directory](img/select_directory.jpg)

---

### 3. Настройка параметров
Обработка автоматически определяет:
- период анализа по найденным файлам `.log`,
- каталог результатов,
- каталог логов.

Каталоги результатов и логов формируются как родительские относительно каталога технологического журнала.  
В поле **Скрипт** указывается путь к файлам исходного кода парсера во временном каталоге.  

![settings_fill](img/settings_fill.jpg)

---

### 4. Контроль CPU
Парсер масштабируется по числу процессов и позволяет ограничивать загрузку процессора параметром **Контроль CPU**.

- Если `Контроль CPU = Один поток` → запуск выполняется **в один процесс** (последовательно).  
- В остальных случаях количество процессов рассчитывается по формуле:

```text
процессов = max(1, min(КоличествоЯдер, КоличествоЯдер * КонтрольCPU_% / 100))
```

где `КонтрольCPU_%` — процент, указанный в настройках обработки.  

Пример: при `Контроль CPU = Оптимально (50% CPU)` на 8-ядерной машине будет использовано `(8 * 0.5) = 4` процесса.  

Параллелится **обработка файлов**: каждый процесс берет свой `.log`, читает его построчно, формирует батчи и пишет промежуточные Parquet-чанки. Затем все чанки объединяются для финальных агрегаций и экспорта в Excel.  

![cpu_control](img/cpu_control.jpg)

---

### 5. Выбор шаблонов анализа
Перейдите на страницу **"Шаблоны анализа"** и нажмите **Подобрать**.  
Откроется форма выбора с готовыми шаблонами. Рекомендуется выбрать все шаблоны из группы *"Технологический аудит"*.  

![select_templates](img/select_templates.jpg)

---

### 6. Настройка каталогов анализа
В указанных ранее каталогах технологического журнала на странице **"Настройка анализа"** выполняется поиск подкаталогов для каждого шаблона анализа.  
Подкаталоги, в которых ищутся файлы `.log`, определяются настройками шаблона и могут быть переопределены в обработке.  

![set_subdirs](img/set_subdirs.jpg)

---

### 7. Запуск анализа
Нажмите большую желтую кнопку **"Запустить анализ"**.  
Для каждого шаблона будет сформирован `config.json`, после чего запустится скрипт Python.  

Ход выполнения отображается в консоли. Дополнительно информация пишется в файл лога.  

![run_analysis](img/run_analysis.jpg)

---

### 8. Результаты анализа
После выполнения всех шаблонов в строках обработки появятся гиперссылки на итоговый файл Excel и файл лога:  

![result_excel](img/result_excel.jpg)

---

### 9. Ручной запуск
Для ручного запуска парсера Python можно нажать команду **"Показать JSON"**.  
Для каждого шаблона будет выведен сформированный `config.json`.  

![show_json](img/show_json.jpg)

## Настройка шаблона анализа

### 1. Основные настройки

Каждый шаблон анализа определяет:
- правила обработки файлов технологического журнала,  
- структуру результирующего файла после анализа.  

#### Обязательные параметры
- **Событие** — укажите, какое событие технологического журнала будет анализироваться.  
- **Колонки отчета** — выберите поля, которые должны попасть в результирующий файл. Каждая колонка отчета это свойство события технологического журнала. Либо как есть либо измененное по формуле. Для свойств можно настраивать "Агрегации" для анализа различной статистики. Подробнее см. раздел *Справочник агрегаций* в [README.md](../README.md) 

![template](img/template.jpg)

#### Работа с колонками
- **Группировка** — перетащите нужные колонки из таблицы *Колонки отчета* в таблицу *Группировка*.  
  - Эти поля станут ключами группировки.  
  - Все остальные колонки, оставшиеся в *Колонках отчета*, будут считаться полями **суммирования**.  

![template_group](img/template_group.jpg)

- **Сортировка** — для задания порядка строк в отчете перетащите выбранные колонки в таблицу *Сортировка*.  

![template_sort](img/template_sort.jpg)

- **Отборы** — для фильтрации данных по значениям перетащите выбранные колонки в таблицу *Отборы*.  

![template_filters](img/template_filters.jpg)

#### Каталоги анализа
На странице **Каталоги анализа** перечисляются имена каталогов (с учетом регистра), в которых будет выполняться поиск событий для анализа.  

![template_subdirs](img/template_subdirs.jpg)

Это удобно в случаях, когда:
- каждое событие или группа похожих событий сохраняется в отдельный каталог,  
- лог-файлы делятся на меньшие части.  

Такой подход помогает:
- уменьшить размеры отдельных файлов `.log`,  
- ускорить их чтение и последующую обработку.  

#### Агрегация «Интервалы»
Отдельно стоит отметить агрегацию **Интервалы** (`intervals_X_Y`).  
Она применяется **только к числовым колонкам** (например, `duration`, `MemoryPeak`, `cpu_time`).

Смысл агрегации: значения разбиваются на диапазоны (интервалы) фиксированного размера, и в отчет выводится процент записей, попавших в каждый из интервалов.

- `X` — шаг интервала (ширина «корзины»).  
- `Y` — количество интервалов.  
- Автоматически добавляется последний интервал «≥ X*Y».

**Пример**
Колонка `duration` (время выполнения), агрегация: `intervals_5_5`  
- `X = 5`, шаг интервала = 5 секунд.  
- `Y = 5`, значит будет 5 интервалов по 5 секунд и один «хвостовой» интервал.  

В отчете появятся столбцы:

| Интервал   | Что показывает                                      |
|------------|-----------------------------------------------------|
| `<5`       | процент записей, где `duration < 5`                 |
| `5-10`     | процент записей, где `5 ≤ duration < 10`            |
| `10-15`    | процент записей, где `10 ≤ duration < 15`           |
| `15-20`    | процент записей, где `15 ≤ duration < 20`           |
| `20-25`    | процент записей, где `20 ≤ duration < 25`           |
| `25>`      | процент записей, где `duration ≥ 25`                |

#### Агрегация «Округление времени»

Агрегация **Округление времени** (`roundtime_Nu`) применяется к колонкам с типом «дата/время» (например, `timestamp`).  
Она позволяет округлять время до заданного интервала и использовать это округленное значение как ключ для группировки.

- `N` — число (длина интервала).  
- `u` — единица измерения (`s` — секунды, `m` — минуты, `h` — часы, `d` — дни).  

**Пример**
Колонка `timestamp`, агрегация: `roundtime_5m`  
- `N = 5`, шаг интервала = 5 минут.  
- `u = m`, значит округляем по минутам.  

Все значения времени будут приведены к ближайшему значению с шагом в 5 минут:  
- `12:01`, `12:02`, `12:04` → `12:00`  
- `12:06`, `12:08`, `12:09` → `12:05`  

**Как интерпретировать**
- Такая агрегация группирует события в равные временные «корзины».  
- Удобно для анализа динамики по времени: количество запросов в минуту, средняя длительность за каждый час и т.п.  
- Позволяет строить временные ряды и видеть пики/провалы нагрузки.


